#!/usr/bin/env python3
"""Generate Pydantic models from JSON Schema.

This script is the source of truth workflow for artifact models.
Run after modifying any schema in schemas/*.schema.json.

Usage:
    uv run python scripts/generate_models.py

The generated file will be written to:
    src/questfoundry/artifacts/generated.py

Exit codes:
    0: Generation successful
    1: Generation failed (schema error, ruff error, etc.)
"""

from __future__ import annotations

import json
import subprocess
import sys
from pathlib import Path
from typing import Any

# Output file location
GENERATED_FILE = Path(__file__).parent.parent / "src/questfoundry/artifacts/generated.py"
SCHEMAS_DIR = Path(__file__).parent.parent / "schemas"

# Header for generated file
GENERATED_HEADER = '''\
"""Auto-generated Pydantic models from JSON Schema.

DO NOT EDIT THIS FILE DIRECTLY.
Run `uv run python scripts/generate_models.py` to regenerate.

Source schemas: schemas/*.schema.json
"""

from __future__ import annotations

from typing import Annotated, Literal

from pydantic import BaseModel, Field, StringConstraints

# Non-empty string type for list items
NonEmptyStr = Annotated[str, StringConstraints(min_length=1)]

'''


def schema_to_python_type(
    prop: dict[str, Any],
    prop_name: str,
    parent_required: set[str],
) -> tuple[str, str]:
    """Convert JSON Schema property to Python type annotation and Field.

    Args:
        prop: The property schema definition.
        prop_name: Name of the property.
        parent_required: Set of required field names from parent object.

    Returns:
        Tuple of (type_annotation, field_definition).
    """
    prop_type = prop.get("type")
    description = prop.get("description", "")

    # Handle const (Literal type)
    if "const" in prop:
        const_val = prop["const"]
        return f'Literal["{const_val}"]', f'"{const_val}"'

    # Handle integer
    if prop_type == "integer":
        field_args = []
        if description:
            field_args.append(f'description="{description}"')
        if "minimum" in prop:
            field_args.append(f"ge={prop['minimum']}")

        # Check if field has a default
        is_required = prop_name in parent_required
        if not is_required:
            type_anno = "int | None"
            field_args.insert(0, "default=None")
        else:
            type_anno = "int"
            # Version field gets default=1
            if prop_name == "version":
                field_args.insert(0, "default=1")

        field_def = f"Field({', '.join(field_args)})" if field_args else "..."
        return type_anno, field_def

    # Handle string
    if prop_type == "string":
        field_args = []
        if description:
            field_args.append(f'description="{description}"')
        if prop.get("minLength"):
            field_args.append(f"min_length={prop['minLength']}")

        is_required = prop_name in parent_required
        if not is_required:
            type_anno = "str | None"
            field_args.insert(0, "default=None")
        else:
            type_anno = "str"

        field_def = f"Field({', '.join(field_args)})" if field_args else "..."
        return type_anno, field_def

    # Handle array
    if prop_type == "array":
        items = prop.get("items", {})
        item_type = items.get("type", "Any")

        # Check if items have minLength constraint
        if item_type == "string" and items.get("minLength"):
            item_type_anno = "NonEmptyStr"
        else:
            item_type_anno = "str" if item_type == "string" else item_type

        field_args = []
        if description:
            field_args.append(f'description="{description}"')
        if prop.get("minItems"):
            field_args.append(f"min_length={prop['minItems']}")

        is_required = prop_name in parent_required
        if not is_required:
            field_args.insert(0, "default_factory=list")

        type_anno = f"list[{item_type_anno}]"
        field_def = f"Field({', '.join(field_args)})" if field_args else "..."
        return type_anno, field_def

    # Handle nested object (will be a reference to another class)
    if prop_type == "object":
        # Generate class name from property name
        class_name = "".join(word.capitalize() for word in prop_name.split("_"))

        is_required = prop_name in parent_required
        if not is_required:
            type_anno = f"{class_name} | None"
            default = "default=None"
        else:
            type_anno = class_name
            default = ""

        field_args = []
        if default:
            field_args.append(default)
        if description:
            field_args.append(f'description="{description}"')

        field_def = f"Field({', '.join(field_args)})" if field_args else "..."
        return type_anno, field_def

    # Fallback
    return "Any", "..."


def generate_nested_class(
    prop_name: str,
    prop_schema: dict[str, Any],
) -> str:
    """Generate a nested Pydantic model class.

    Args:
        prop_name: Property name (used for class naming).
        prop_schema: The object schema definition.

    Returns:
        Python class definition as string.
    """
    class_name = "".join(word.capitalize() for word in prop_name.split("_"))
    description = prop_schema.get("description", f"{class_name} model.")
    properties = prop_schema.get("properties", {})
    required = set(prop_schema.get("required", []))

    lines = [f"class {class_name}(BaseModel):"]
    lines.append(f'    """{description}"""')
    lines.append("")

    # Sort properties for deterministic output
    for field_name in sorted(properties.keys()):
        field_schema = properties[field_name]
        type_anno, field_def = schema_to_python_type(field_schema, field_name, required)
        lines.append(f"    {field_name}: {type_anno} = {field_def}")

    lines.append("")
    return "\n".join(lines)


def generate_artifact_class(
    schema: dict[str, Any],
    artifact_type: str,
) -> tuple[str, list[str]]:
    """Generate the main artifact Pydantic model class.

    Args:
        schema: The full JSON schema.
        artifact_type: Type identifier (e.g., "dream").

    Returns:
        Tuple of (class_definition, list_of_nested_class_definitions).
    """
    title = schema.get("title", f"{artifact_type.upper()} Artifact")
    description = schema.get("description", f"{title} model.")
    properties = schema.get("properties", {})
    required = set(schema.get("required", []))

    class_name = f"{artifact_type.capitalize()}Artifact"
    nested_classes: list[str] = []

    lines = [f"class {class_name}(BaseModel):"]
    lines.append(f'    """{title} - {description}"""')
    lines.append("")

    # Sort properties for deterministic output
    for field_name in sorted(properties.keys()):
        field_schema = properties[field_name]

        # Handle nested objects - generate separate class
        if field_schema.get("type") == "object" and "properties" in field_schema:
            nested_class = generate_nested_class(field_name, field_schema)
            nested_classes.append(nested_class)

        type_anno, field_def = schema_to_python_type(field_schema, field_name, required)
        lines.append(f"    {field_name}: {type_anno} = {field_def}")

    lines.append("")
    return "\n".join(lines), nested_classes


def generate_from_schema(schema_path: Path) -> str:
    """Generate Python code from a JSON schema file.

    Args:
        schema_path: Path to the JSON schema file.

    Returns:
        Generated Python code as string.
    """
    with schema_path.open() as f:
        schema = json.load(f)

    # Extract artifact type from filename (e.g., "dream" from "dream.schema.json")
    artifact_type = schema_path.stem.replace(".schema", "")

    artifact_class, nested_classes = generate_artifact_class(schema, artifact_type)

    # Nested classes come first (dependencies)
    code_parts = [*nested_classes, artifact_class]
    return "\n".join(code_parts)


def format_with_ruff(file_path: Path) -> bool:
    """Format generated file with ruff.

    Args:
        file_path: Path to the file to format.

    Returns:
        True if formatting succeeded, False otherwise.
    """
    try:
        # Run ruff format
        result = subprocess.run(
            ["uv", "run", "ruff", "format", str(file_path)],
            capture_output=True,
            text=True,
            check=False,
        )
        if result.returncode != 0:
            print(f"Ruff format failed: {result.stderr}", file=sys.stderr)
            return False

        # Run ruff check with fixes
        result = subprocess.run(
            ["uv", "run", "ruff", "check", "--fix", str(file_path)],
            capture_output=True,
            text=True,
            check=False,
        )
        if result.returncode != 0:
            print(f"Ruff check failed: {result.stderr}", file=sys.stderr)
            return False

        return True
    except FileNotFoundError:
        print("ruff not found, skipping formatting", file=sys.stderr)
        return True


def main() -> int:
    """Generate models from all schema files.

    Returns:
        Exit code (0 for success, 1 for failure).
    """
    # Find all schema files
    schema_files = sorted(SCHEMAS_DIR.glob("*.schema.json"))
    if not schema_files:
        print(f"No schema files found in {SCHEMAS_DIR}", file=sys.stderr)
        return 1

    print(f"Found {len(schema_files)} schema file(s)")

    # Generate code for each schema
    all_code = [GENERATED_HEADER]
    artifact_types: list[str] = []

    for schema_path in schema_files:
        print(f"  Processing {schema_path.name}...")
        try:
            code = generate_from_schema(schema_path)
            all_code.append(code)
            artifact_type = schema_path.stem.replace(".schema", "")
            artifact_types.append(f"{artifact_type.capitalize()}Artifact")
        except (json.JSONDecodeError, KeyError) as e:
            print(f"Error processing {schema_path}: {e}", file=sys.stderr)
            return 1

    # Add type alias for all artifact types
    if artifact_types:
        all_code.append("# Type alias for artifact types")
        all_code.append(f"ArtifactType = {' | '.join(artifact_types)}")
        all_code.append("")

    # Write generated file
    generated_code = "\n".join(all_code)
    GENERATED_FILE.parent.mkdir(parents=True, exist_ok=True)
    GENERATED_FILE.write_text(generated_code)
    print(f"Generated {GENERATED_FILE}")

    # Format with ruff
    if not format_with_ruff(GENERATED_FILE):
        print("Warning: ruff formatting failed", file=sys.stderr)
        return 1

    print("Done!")
    return 0


if __name__ == "__main__":
    sys.exit(main())
